\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

%\usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Temporal Activity Detection in Untrimmed Videos with RNN}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
    Alberto Montes \\
    Polytechnic University of Catalonia \\
    Barcelona, Catalonia/Spain \\
    \texttt{al.montes.gomez@gmail.com} \\
    \And
    Amaia Salvador \\
    Image Processing Group \\
    Polytechnic University of Catalonia \\
    Barcelona, Catalonia/Spain \\
    \texttt{amaia.salvador@upc.edu} \\
    \And
    Xavi Giro-i-Nieto \\
    Image Processing Group \\
    Polytechnic University of Catalonia \\
    Barcelona, Catalonia/Spain \\
    \texttt{xavier.giro@upc.edu} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}

    In the later years the applications of Deep Learning techniques have moved from images to videos due to the increase of computational resources available. In this work, we propose a simple pipeline to classify and temporally localize activities on videos. The framework consist on a first stage to extract features from video segments using a 3D CNN and then a RNN which will predict a classification for each segment of the video. Some post-processing was applied at the output to be able to temporally localize activities on each video.

\end{abstract}

\section{Introduction}

Recognizing activities in videos has become a hot topic over the last years due to the continuous increase of video cameras devices and online repositories. 
This large amount of data requires an automatic indexing to be accessed after capture.
The recent advances in video coding, storage and computational resources have boosted research in the field towards new and more efficient solutions for organizing and retrieving video content.

Impressive progress has been reported in the recent literature for video classification %% cites
Recently it was starting facing the challenge to detect activities in untrimmed videos and this motivate another challenge topic: temporal localization of activities in videos. This task present a lot of real applications such as automatic trimmed of videos to keep the most interesting part. The possibilities are endless.

\section{Related Work}

The activity classification and temporal location tasks have been faced lately in Challenges such as the THUMOS~\cite{THUMOS15} and UCF101~\cite{UCF101}. 







\section*{References}
{\small
\bibliographystyle{plainnat}
\bibliography{references}
}

\end{document}
